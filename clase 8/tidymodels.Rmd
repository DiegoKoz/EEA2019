---
title: "Tidy Models, una introducción^[basado en las notas de Edgar Ruiz https://rviews.rstudio.com/2019/06/19/a-gentle-intro-to-tidymodels/]"
author: "Diego Kozlowski yJuan Manuel Barriola"
output: html_notebook
---


Las librerías de _Tidymodels_ fueron realizadas con el objetivo de incorporarse al flujo de trabajo del _tidyverse_. A diferencia de versiones previas, como Caret, son modulares, y cada librería tiene un objetivo acotado. 

![](img/ds.png)

Dentro del paquete _tidymodels_ se encuentran otros paquetes, cómo: 

![](img/tidymodels.png)


- `rsample` - Diferentes tipos de remuestreo
- `recipes` - Organización de las transformaciones para el preprocesamiento de la información de forma tal que sea lo más reproducible posible. En este sentido, se acerca a los _pipelines_ de sk-learn
- `parnip` - Un interfaz común para crear modelos, independientemente de la implementación (paquete)
- `yardstick` - Metricas de performance del modelo.


```{r echo=TRUE, message=FALSE, warning=FALSE}
library(tidymodels)
```

![](img/library_tidymodels.png)

Veamos un ejemplo con iris


## Preprocesamiento

### Remuestreo de datos

![](img/rsample_logo.png){width=100}

con `rsample::initial_split()` creamos una división entre train y test

```{r}
iris_split <- initial_split(iris, prop = 0.6)
iris_split
```
cuando llamamos al objeto `iris_split` nos muestra la cantidad de elementos en train/test/total

Si queremos recuprar el dataset de entrenamiento, utilizamos el comando `training()`

```{r}
iris_split %>%
  training()  
```

### Receta de transformaciones

![](img/recipes_logo.png){width=100}

Con `recipes::recipe()` indicamos que comenzamos un pipeline de preprocesamiento, indicando cual es la variable a predecir, con `Species ~.`.

El objetivo de realizar el preprocesamiento de esta manera es que para muchas etapas del preprocesamiento, como puede ser el cálculo de la media para la imputación, sólo podemos utilizar la información del set de entrenamiento para evitar el _information leaking_. Por ello, si construimos un pipeline donde se calcula todo sobre entrenamiento, después es más sencillo reutilizarlo en test, sin cometer errores de este tipo.

utilizando `recipes` __entrenamos__ el preprocesamiento.

- `recipe()` Empieza un nuevo set de transformaciones para ser aplicadas. 

- `prep()` Es el último paso, que indica que hay que ejecutar toods los pasos anteriores sobre los datos.

Cada tranformación es un _step_(paso). Las funciones son tipos específicos de pasos. En este caso utilizamos:

- `step_corr()` Elimina las variables que tienen una correlación alta con otras variables
- `step_center()` Centra los datos para que tengan media cero
- `step_scale()` Normaliza los datos para que tengan desvío estandar de 1.

También hay una serie de funciones para seleccionar las variables sobre las que se va a operar:

- `all_predictors` y `all_outcomes` ayudan a espcificar sobre las variables predictivas y predictoras.
- Se puede definir otros roles con `update_role` y luego seleccionarlas vía `has_role`
- `all_numeric`, `all_nominal` y `has_type` permite elegir las variables según su tipo.

```{r warning=FALSE}
iris_recipe <- training(iris_split) %>%
  recipe(Species ~.) %>%
  step_corr(all_predictors()) %>%
  step_center(all_predictors(), -all_outcomes()) %>%
  step_scale(all_predictors(), -all_outcomes()) %>%
  prep()

iris_recipe
```

en `iris_recipe` tenemos la __receta__ del preprocesamiento, pero aún no se aplicó sobre ningún set de datos.

### Aplicamos la receta en los datos de train y test


Dado que la receta fue construida con los datos de entrenamiento, este dataset ya se encuentra implícito en `iris_recipe`. Para extraerlo, ya preprocesado, utilizamos la función `juice` directamente sobre la receta.


```{r warning=FALSE}
iris_training <- juice(iris_recipe)

 iris_training
```


Con la función `bake()` podemos aplicar la _receta_ que preparamos antes para los datos de test. Para ello el primer objeto que pasamos es la _receta_ y como parámetro de _bake_ pasamos el dataset de test (recuperado con la función `testing` de rsample)

```{r warning=FALSE}
iris_testing <- iris_recipe %>%
  bake(testing(iris_split)) 

iris_testing
```


## Entrenamiento de modelos

![](img/parsnip_logo.png){width=100}

En R hay muchos paquetes que implementan el mismo tipo de modelo. Normalmente cada implementación define los parámetros del modelo de forma distinta. Por ejemplo, para el modelo Random Forest, la librería `ranger` define el número de árboles como num.trees, mientras que la librería `randomForest` lo nombra ntree. 

Al igual que la vieja librería caret, tidymodels remplaza la interfaz, pero no el paquete. Es decir, no es una nueva implementación de los modelos, sino una interfaz que unifica las diferentes sintaxis.

- En este caso, la función `rand_forest` incializa el modelo de Random Forest, definiendo sus parámetros.
- La función `set_engine` sirve para especificar qué implementación utilizar.
- Para entrenar el modelo, se utiliza la función `fit`

```{r}
iris_ranger <- rand_forest(trees = 100, mode = "classification") %>%
  set_engine("ranger") %>%
  fit(Species ~ ., data = iris_training)

iris_ranger
```


```{r}
iris_rf <-  rand_forest(trees = 100, mode = "classification") %>%
  set_engine("randomForest") %>%
  fit(Species ~ ., data = iris_training)

iris_rf
```


```{r}
iris_noengine <- rand_forest(trees = 100, mode = "classification") %>%
  fit(Species ~ ., data = iris_training)
```


## Predicciones

Para predecir los datos de test utilizamos la conocida función `predict`. Sin embargo, cuando utilizamos esta función sobre un objeto de la librería `parsnip` devuelve un _tibble_

```{r}
predict(iris_ranger, iris_testing)
```

Para agregar las predicciones a los datos de test podemos utilizar la función `bind_cols`

```{r}
iris_ranger %>%
  predict(iris_testing) %>%
  bind_cols(iris_testing)  
```


## Validación

![](img/yardstick_logo.png){width=100}

Con la función `yardstick::metrics()` podemos medir la performance del modelo. Elige automáticamente las métricas apropiadas dado el tipo de modelo. Necesitmaos aclarar cuales son los datos predichos,_estimate_ y reales, _truth_.

```{r}
iris_ranger %>%
  predict(iris_testing) %>%
  bind_cols(iris_testing) %>%
  metrics(truth = Species, estimate = .pred_class)
```

```{r}
iris_rf %>%
  predict(iris_testing) %>%
  bind_cols(iris_testing) %>%
  metrics(truth = Species, estimate = .pred_class)
```

## Metricas por clasificador

Si en el predict elegimos `type="prob"` 

```{r}
iris_ranger %>%
  predict(iris_testing, type = "prob")  
```



```{r}
iris_probs <- iris_ranger %>%
  predict(iris_testing, type = "prob") %>%
  bind_cols(iris_testing)

iris_probs
```

Con el tibble iris_probs es fácil calcular métodos de curva, como la ROC, utilizando la función `roc_curve`

```{r}
iris_probs%>%
  roc_curve(Species, .pred_setosa:.pred_virginica)
```

finalmente, con la función `autoplot` podemos graficar las curvas. Dado que el resultado es un objeto ggplot, podemos hacer otras modificaciones posteriores. 

```{r}
iris_probs%>%
  roc_curve(Species, .pred_setosa:.pred_virginica) %>%
  autoplot()+
  ggthemes::theme_fivethirtyeight()+
  labs(title = 'Curvas ROC')
```

Si queremos un tibble con la clase predicha y la probabilidad de cada clase, podemos utilizar `bind_cols` para juntar los resultados de ambos tipos

```{r}
predict(iris_ranger, iris_testing, type = "prob") %>%
  bind_cols(predict(iris_ranger, iris_testing)) %>%
  bind_cols(select(iris_testing, Species))
```



si utilizamos `metrics` sobre estos resultados, obtenemos además de accuracy y kap, el log loss y el area debajo de la curva ROC.

```{r}
predict(iris_ranger, iris_testing, type = "prob") %>%
  bind_cols(predict(iris_ranger, iris_testing)) %>%
  bind_cols(select(iris_testing, Species)) %>%
  metrics(truth=Species, .pred_setosa:.pred_virginica, estimate = .pred_class)
```


